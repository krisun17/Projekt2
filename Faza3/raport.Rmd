---
title: "Modele predykcji zachorowań na raka piersi w Polsce"
author: "Patrycja Matys, Jan Rosa, Krzysztof Rutkowski, Magda Sobiczewska"
date: "17 czerwca 2016"
output: 
  html_document:
    fig_caption: yes
    toc: true
---
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
load(file="regresja_dane.Rdata")
library(knitr)
```

#Wprowadzenie

## Przygotowanie danych
Do predykcji przygotowaliśmy dane dotyczące powiatów, gdzie zmienną objaśnianą jest znormalizowany
(przez liczbę osób w powiecie) **odsetek chorych na raka piersi**. Zaś zmiennymi objaśniającymi
są czynniki wymienione w częsci poświećonej metodologii. Poniższa tabela przedstawia omawiane zmienne.
```{r}
kable(head(y11[,1:6]))
kable(head(y11[,7:12]))
kable(head(y11[,13:18]))
```

## Sposób predykcji

Zdoloność predykcyjną modeli zbadaliśmy estymując model na podstawie danych z **2011** roku, a następnie porównujac predykcję modelu na **2012** roku z rzeczywistymi wartościami. Za kryterium obraliśmy błąd RMSE.

```{r include=FALSE}
mse <- function(pred, y) {
  return(mean((pred-y)^2, na.rm=TRUE))
}
rmse <- function(pred, y) {
  return(sqrt(mean((pred-y)^2, na.rm=TRUE)))
}
```

#Użyte modele
Używaliśy następujących metod:    
<ul>
<li> regresja liniowa </li>
<li> xgboost </li>
</ul>


##########
Widzimy, że najlepiej sprawdzały się **regresja liniowa i xgboost**. Te metody omówimy szerzej.

##Metodologia i wybór czynników

Na podstawie literatury przedmiotu, w poprzedniej fazie zauważyliśmy że następujące czynniki są ważne:
<ul>
<li>wiek</li>
<li>płeć</li> 
<li>stężenie szkodliwych pyłów</li>
<li>stężenie szkodliwych gazów</li>
<li>urbanizację</li> 
<li>gęstość zaludnienia</li>
</ul> 


W trzeciej fazie postanowiliśmy dodać także czynniki:
<ul>
<li>spożycie alkoholu alkoholu wśród kobiet (dane dla województw)</li> 
<li>spożycie alkoholu alkoholu wśród mężczyzn (dane dla województw)</li> 
<li>otyłość wśród kobiet (dane dla województw)</li> 
<li>otyłość wśród mężczyzn (dane dla województw)</li> 
<li>liczbę osób zarejestrowanych w poradniach psychologicznych (o zaburzeniach nie alkoholowych i nie schizofrenicznych)</li> 
<li>liczbę osób z zaburzeniami psychicznymi (dane dla województw)</li>
<li>liczbę osób chorych w poprzednim okresie</li>
</ul>
Za jedne z najważniejszych przyczyn nowotworu złośliwego piersi jest uznawane spożycie alkoholu oraz otyłość, z tego powodu dodaliśmy pierwsze cztery czynniki. Za bardzo ważny determinant uznawany jest również wysoki poziom stresu, który przybliżać mają zmienne opisujące liczbę osób z problemami psychicznymi. 

    
##Modele liniowe
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(knitr)
mse <- function(pred, y) {
  return(mean((pred-y)^2, na.rm=TRUE))
}
rmse <- function(pred, y) {
  return(sqrt(mean((pred-y)^2, na.rm=TRUE)))
}
```
W pierwszej kolejności oszacowalismy i przetestowaliśmy modele linowe. Moc predykcyjną przetestowaliśmy opisaną wyżej metodą.

Z modeli linowych na początku oszacowano zwykły model regresji. W zbiorze zmiennych objaśnianych znalazły się wszystkie rozważane przez nas zmienne, a także interakcje między wiekiem a urbanizacją. Pierwszy model wykorzystywał wszystkie zmienne, drugi czynniki wybrane na podstawie kryterium BIC. Otrzymano następujące modele:

```{r cars, echo=FALSE}
#print(getwd())
load(file="regresja_dane.Rdata")
fit1_normal1<-lm(zm_dec.x~ GAZY +GESTOSC+ZIELONE+ URBANIZACJA+
                   ZAGROZENIA+PYLY+GENDER*Fotytly*URBANIZACJA+
                   GENDER*Falkohol*URBANIZACJA+GENDER*Motytly+GENDER*Malkohol+
                   URBANIZACJA+as.factor(AGE_GROUP)*URBANIZACJA+nsrednia.y+zsrednia.y+nsrednia.y*URBANIZACJA+opoznienie, data=y11)

fit1_aic<-step(fit1_normal1,data=grupa_m3, direction="backward",criterion = "BIC", trace=0)
summary(fit1_normal1)
summary(fit1_aic)

```

Jak widać w obu przypadkach, za istotne zmienne, na podstawie testu t, należy uznać: urbanizację, gestość zaludnenia, wiek, poziom spożycia alkoholu wśród kobiet, a także liczbę osób zarejestrowanych w poradniach psychologicznych.  

```{r kable, echo=FALSE, warning=FALSE}
res <- data.frame(matrix(ncol=2, nrow=2))
colnames(res) <- c("model", "wyniki")
res$model <- c("normal", "aic")
res$wyniki <- c(rmse(predict(fit1_normal1,y12), y12$zm_dec.x)*10^5, 
                rmse(predict(fit1_aic,y12), y12$zm_dec.x)*10^5)
kable(res)

```

Następnie na oszacowano uogólnione modele regresjiwykorzystujące wszystkie zmienne, oraz zmienne wybrane na podstawie kryterium BIC. Analogicznie do modeli regresji liniowej przetestowano ich moc predykcyjną.
Z współczynnik alfa przyjęto:
<ul>
<li>1.0 (lasso)</li>
<li>0.5</li> 
<li>0.25</li> 
<li>0.0 (ridge)</li> 
</ul>

```{r, echo=FALSE}
f <- as.formula(zm_dec.x~ GAZY +GESTOSC+ZIELONE+ URBANIZACJA+
                  ZAGROZENIA+PYLY+Fotytly*URBANIZACJA+
                  Falkohol+Motytly+GENDER*Malkohol+
                  URBANIZACJA+as.factor(AGE_GROUP)+nsrednia.y+zsrednia.y
                +nsrednia.y*URBANIZACJA+opoznienie)
                
options(na.action='na.omit')

x1 <- model.matrix(f, y11,na.action=NULL)
x2<-as.data.frame(x1)
y1 <- na.omit(y11)
library(glmnet)

wynik_cv_lasso<-cv.glmnet(x=x1,y=as.matrix(y1[,17]), alpha=1)
wynik_cv_ridge<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=0)
wynik_cv_pol<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/2)
wynik_cv_pol1<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/4)


y12<-subset(y12, TERYT4!=1461)
y2 <- na.omit(y12)
y21 <- y12[complete.cases(y12),]

wynik_cv_lasso_pred<-predict.cv.glmnet(object =wynik_cv_lasso,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_ridge_pred<-predict.cv.glmnet(object =wynik_cv_ridge,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_pol_pred<-predict.cv.glmnet(object =wynik_cv_pol,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_pol1_pred<-predict.cv.glmnet(object =wynik_cv_pol1,newx=model.matrix(f, y12,na.action=NULL),)


```

Wyniki dla uogólnionych modeli:

```{r, echo=FALSE}
res <- data.frame(matrix(ncol=2, nrow=4))
colnames(res) <- c("model", "wyniki")
res$model <- c("lasso", "ridge", "alfa 0.5", "alfa 0.25")
res$wyniki <- c(rmse(y2[,17], wynik_cv_lasso_pred)*10^5, 
                rmse(y2[,17], wynik_cv_ridge_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol1_pred)*10^5)
kable(res)
```


```{r, echo=FALSE}
f1<-formula(fit1_aic)

x1 <- model.matrix(f1, y11,na.action=NULL)
y1 <- na.omit(y11)


wynik_cv_lasso<-cv.glmnet(x=x1,y=as.matrix(y1[,17]), alpha=1)
wynik_cv_ridge<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=0)
wynik_cv_pol<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/2)
wynik_cv_pol1<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/4)



y2 <- na.omit(y12)

wynik_cv_lasso_pred<-predict.cv.glmnet(object =wynik_cv_lasso,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_ridge_pred<-predict.cv.glmnet(object =wynik_cv_ridge,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_pol_pred<-predict.cv.glmnet(object =wynik_cv_pol,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_pol1_pred<-predict.cv.glmnet(object =wynik_cv_pol1,newx=model.matrix(f1, y12,na.action=NULL),)


res <- data.frame(matrix(ncol=2, nrow=4))
colnames(res) <- c("model", "wyniki")
res$model <- c("lasso", "ridge", "alfa 0.5", "alfa 0.25")
res$wyniki <- c(rmse(y2[,17], wynik_cv_lasso_pred)*10^5, 
                rmse(y2[,17], wynik_cv_ridge_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol1_pred)*10^5)
kable(res)

```

Ostateczne wyniki przedstawia tabela:

```{r}
head(res)
```

Ostatecznie, przetestowanie mocy predykcyjnej modeli na danych z 2012 roku wskazało iż najlepiej radzi sobie model liniowy, z zestawem zmiennych wybranych na podstawie kryterium BIC.  

Przeprowadzono także analizy dla modeli estymowanych osobno dla każdej płci, jednak ich moc predykcyjna okazała sie zdecydowanie gorsza.


##Pozostałe modele
Przetestowaliśmy również szereg innych modeli. Analiza została wykonana z wykorzystaniem pakietu "caret"
oraz przeszukiwanie kombinacji parametrów, które dają najlepsze wyniki. Do doboru parametrów użyliśmy
10-krotnej kroswalidacji, zaś walidację wykonaliśmy na zbiorze z 2012 roku, tak jak dla modeli liniowych.
Przetestowaliśmy następujące modele:
<ul>
<li>random forest</li>
<li>gradient boosting</li> 
<li>gradient boosting z selekcją atrybutów</li> 
<li>SVM</li> 
<li>knn z metryką ważoną przez ważność atrybutu</li>
</ul>
Selekcję atrybutów dla boostingu wykonywaliśmy za pomocą korelacji Pearsona.
Dla metody knn, przeskalowaliśmy wszystkie atrybuty, oraz pomnożyliśmy każdą cechę przez wagę uzyskaną
z korelacji między zmienną decyzyjną:

```{r, eval=FALSE}
scaled.data <- data.frame(scale(data))
weights <- rank.correlation(dec ~ ., scaled.data)$attr_importance
knn.data <- t( t(scaled.data) * weights)
```

Uzyskaliśmy następujące wyniki:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
load(file="svmFit.Rdata")
load(file="gbmFit.Rdata")
load(file="gbmFitSel.Rdata")
load(file="knnFit.Rdata")
load(file="rfFit.Rdata")
load(file="knn_data.Rdata")
res <- data.frame(matrix(ncol=2, nrow=5))
colnames(res) <- c("model", "wyniki")
res$model <- c("gbm z selekcją", "gbm", "knn", "random forest", "svm")
res$wyniki <- c(rmse(y2[,17], predict(gbmFitSel, y2[,-17]))*10^5, 
                rmse(y2[,17], predict(gbmFit, y2[,-17]))*10^5,
                rmse(knn.data[,17], predict(knnFit, knn.data[,-17]))*10^5,
                rmse(y2[,17], predict(rfFit, y2[,-17]))*10^5,
                rmse(y2[,17], predict(svmFit, y2[,-17]))*10^5)
kable(res)
```

Widzimy, że najlepsze wyniki zostały uzyskanę metodą boostingu z selekcją atrybutów.

#Końcowy model

Na podstawie analizy błędów zdecydowaliśmy się na zastosowanie modelu "mieszanego", który składa się z __gradient boosting__ oraz __regresji liniowej__.

Opis wybranego modelu:
<ul>
<li>nie rozpatrujemy podziału na grupy wiekowe (nie zauważyliśmy znaczących różnic)</li>
<li>rozpatrujemy podział na płeć</li>
<li>dla mężczyzn stosujemy model gradient boosting</li>
<li>dla kobiet rozpatrujemy podział na TERYT,  odcięcia zostały wykonane na podstawie funkcji:</li>
</ul>

```{r, eval=FALSE}
teryt.groups$is_linear <- teryt.groups$bool_difs < 0 & teryt.groups$difs < -1e-05 
teryt.groups$is_boost <- teryt.groups$bool_difs > 0 & teryt.groups$difs > 1e-05 
teryt.groups$clf <- teryt.groups$is_linear * 1 + teryt.groups$is_boost * -1
```
 
zatem w zależności od wielkości różnic średnich znaków (bool_difs) oraz różnic w średnich (difs) (progi +/-1e-05 zostały dobrane na podstawie Wykresu błędów -  _patrz poniżej_) stosujemy regresję liniową (clf=1) lub gradient boosting (clf=-1) oraz zdecydowaliśmy, że w przypadku braku wyraźnej różnicy między modelami (clf=0) zastosujemy gradient boosting.

__Wykres błędów__ (oś pozioma to numer TERYT):

<center>
<img src="roznice.png" />
</center>

Powyższy opis ilustruje drzewo decyzyjne:

<center>
<img src="drzewo.png" />
</center>

#Prezentacja wyników 

Na poniższych kartogramach prezentujemy predykcję na rok 2013 odsetek zachorowań z podziałem na płeć:

<center>
<img src="kobiety.png" />

<img src="mezczyzni.png" />
<center/>

#Wnioski
