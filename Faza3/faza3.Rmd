---
title: "Modele predykcji zachorowañ na raka piersi w Polsce"
author: "Patrycja Matys, Jan Rosa, Krzysztof Rutkowski, Magda Sobiczewska"
date: "17 czerwca 2016"
output: 
  html_document:
    fig_caption: yes
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
load(file="regresja_dane.Rdata")
library(knitr)
library(caret)
library(glmnet)
library(pls)
library(lars)
library(markdown)
```

#Wprowadzenie
W prezentacji poka¿emy w jaki sposób staraliœmy siê wybraæ model predykcji odsetka zachorowañ na raka piersi w danym powiecie. Za czynniki mog¹ce wp³ywaæ na odsetek zachorowañ wybraliœmy:
<ul>

<li> p³eæ </li> 
<li> wiek </li>
<li> stê¿enie szkodliwych substancji w powietrzu </li>
<li> gêstoœæ zaludnienia </li>
<li> urbanizacjê </li>
<li> uci¹¿liwe warunki pracy </li>
<li> tereny zielone </li>
<li> oty³oœæ zarówno dla kobiet jak i mê¿czyzn</li>
<li> wysokie spo¿ycie alkoholu zarówno dla kobiet jak i mê¿czyzn</li>
<li> liczbê osób zerejestrowanych w poradniach psychiatrycznych </li>
<li> liczbê osób z zabrzeniami psychicznymi </li>

<li> liczbê osób chorych w poprzednim okresie </li>

</ul> 

## Przygotowanie danych
Do predykcji przygotowaliœmy dane dotycz¹ce powiatów, gdzie zmienn¹ objaœnian¹ jest znormalizowany
(przez liczbê osób w powiecie) **odsetek chorych na raka piersi**. Zaœ zmiennymi objaœniaj¹cymi
s¹ czynniki wymienione wy¿ej. Poni¿sza tabela przedstawia omawiane zmienne.
```{r}
kable(head(y11[,1:6]))
kable(head(y11[,7:12]))
kable(head(y11[,13:18]))
```

## Sposób predykcji

Zdolonosæ predykcyjn¹ modeli zbadaliœmy estymuj¹c model na podstawie danych z **2011** roku, a nast¹pnie porównujac predykcjê modelu na **2012** roku z rzeczywistymi wartoœciami. Za kryterium obraliœmy b³¹d œredniokwadratowy. 

```{r include=FALSE}
mse <- function(pred, y) {
  return(mean((pred-y)^2, na.rm=TRUE))
}
rmse <- function(pred, y) {
  return(sqrt(mean((pred-y)^2, na.rm=TRUE)))
}
```

#U¿yte modele
U¿ywaliœmy nastêpuj¹cych metod:    
<ul>
<li> regresja liniowa </li>
<li> xgboost </li>
</ul>


##########
Widzimy, ¿e najlepiej sprawdza³y siê **regresja liniowa i xgboost**. Te metody omówimy szerzej.


#Regresja liniowa
Z modeli linowych na pocz¹tku oszacowaliœmy zwyk³y model regresji liniowej. W zbiorze zmiennych objaœnianych znalaz³y siê wszytskie rozwa¿ane przez nas zmienne. Dodaliœmy tak¿e interakcje miêdzy zmiennymi wiek a urbanizacja. Otrzymaliœmy nastêpuj¹ce modele.

```{r cars}
fit1_normal1<-lm(zm_dec.x~ GAZY +GESTOSC+ZIELONE+ URBANIZACJA+
                   ZAGROZENIA+PYLY+GENDER*Fotytly*URBANIZACJA+
                   GENDER*Falkohol*URBANIZACJA+GENDER*Motytly+GENDER*Malkohol+
                   URBANIZACJA+as.factor(AGE_GROUP)*URBANIZACJA+nsrednia.y+zsrednia.y+nsrednia.y*URBANIZACJA+opoznienie,
                 data=y11)

fit1_aic<-step(fit1_normal1,data=grupa_m3, direction="backward",criterion = "BIC")

```
Model wybrany na podstawie kryterium BIC radzi sobie nieco lepiej od modelu wykorzystujacego wszytskie zmienne.

```{r kable, echo=FALSE}
res <- data.frame(matrix(ncol=2, nrow=2))
colnames(res) <- c("model", "wyniki")
res$model <- c("normal", "aic")
res$wyniki <- c(rmse(predict(fit1_normal1,y12), y12$zm_dec.x)*10^5, 
                rmse(predict(fit1_aic,y12), y12$zm_dec.x)*10^5)
kable(res)
```

Nastêpnie oszacowaliœmy uogólnione modele regresji wykorzystuj¹ce wszytskie zmienne.
Za wspó³czynnik alfa przyjêliœmy:
<ul>
<li>1.0 (lasso)</li>
<li>0.5</li> 
<li>0.25</li> 
<li>0.0 (ridge)</li> 
</ul>
```{r, echo=FALSE}
f <- as.formula(zm_dec.x~ GAZY +GESTOSC+ZIELONE+ URBANIZACJA+
                  ZAGROZENIA+PYLY+Fotytly*URBANIZACJA+
                  Falkohol+Motytly+GENDER*Malkohol+
                  URBANIZACJA+as.factor(AGE_GROUP)+nsrednia.y+zsrednia.y
                +nsrednia.y*URBANIZACJA+opoznienie)
                
options(na.action='na.omit')

x1 <- model.matrix(f, y11,na.action=NULL)
x2<-as.data.frame(x1)
y1 <- na.omit(y11)

wynik_cv_lasso<-cv.glmnet(x=x1,y=as.matrix(y1[,17]), alpha=1)
wynik_cv_ridge<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=0)
wynik_cv_pol<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/2)
wynik_cv_pol1<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/4)


y12<-subset(y12, TERYT4!=1461)
y2 <- na.omit(y12)
y21 <- y12[complete.cases(y12),]

wynik_cv_lasso_pred<-predict.cv.glmnet(object =wynik_cv_lasso,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_ridge_pred<-predict.cv.glmnet(object =wynik_cv_ridge,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_pol_pred<-predict.cv.glmnet(object =wynik_cv_pol,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_pol1_pred<-predict.cv.glmnet(object =wynik_cv_pol1,newx=model.matrix(f, y12,na.action=NULL),)
```
Wyniki dla uogólnionych modeli:
```{r, echo=FALSE}
res <- data.frame(matrix(ncol=2, nrow=4))
colnames(res) <- c("model", "wyniki")
res$model <- c("lasso", "ridge", "alfa 0.5", "alfa 0.25")
res$wyniki <- c(rmse(y2[,17], wynik_cv_lasso_pred)*10^5, 
                rmse(y2[,17], wynik_cv_ridge_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol1_pred)*10^5)
kable(res)
```

Nastêpnie przeanalizowaliœmy modele **glm** dla tego samego zestawu zmiennych jak w modelu linowym wybranym na podstawie krytrium **BIC**. Analogicznie przetestowaliœmy ich moc predykcyjn¹.

```{r, echo=FALSE}
f1<-formula(fit1_aic)

x1 <- model.matrix(f1, y11,na.action=NULL)
y1 <- na.omit(y11)

wynik_cv_lasso<-cv.glmnet(x=x1,y=as.matrix(y1[,17]), alpha=1)
wynik_cv_ridge<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=0)
wynik_cv_pol<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/2)
wynik_cv_pol1<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/4)

y2 <- na.omit(y12)

wynik_cv_lasso_pred<-predict.cv.glmnet(object =wynik_cv_lasso,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_ridge_pred<-predict.cv.glmnet(object =wynik_cv_ridge,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_pol_pred<-predict.cv.glmnet(object =wynik_cv_pol,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_pol1_pred<-predict.cv.glmnet(object =wynik_cv_pol1,newx=model.matrix(f1, y12,na.action=NULL),)

res <- data.frame(matrix(ncol=2, nrow=4))
colnames(res) <- c("model", "wyniki")
res$model <- c("lasso", "ridge", "alfa 0.5", "alfa 0.25")
res$wyniki <- c(rmse(y2[,17], wynik_cv_lasso_pred)*10^5, 
                rmse(y2[,17], wynik_cv_ridge_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol1_pred)*10^5)
kable(res)
```

Ostatecznie wiêc przetestowanie mocy predykcyjnej modeli na danych z 2012 roku wskaza³o, i¿ najlepiej radzi sobie **model liniowy, z zestawiem zmiennych wybranych na podstawie kryterium BIC**.  

Przeprowadziliœmy tak¿e analizy dla modeli estymowyanych osobno dla obu p³ci, jednak ich moc predykcyjna okaza³a siê zdecydowanie gorsza.


##Pozosta³e modele

#Koñcowy model

Na podstawie analizy b³êdów zdecydowaliœmy siê na zastosowanie modelu "mieszanego", który sk³ada siê z __gradient boosting__ oraz __regresji liniowej__.

Opis wybranego modelu:
<ul>
<li>nie rozpatrujemy podzia³u na grupy wiekowe (nie zauwa¿yliœmy znacz¹cych ró¿nic)</li>
<li>rozpatrujemy podzia³ na p³eæ</li>
<li>dla mê¿czyzn stosujemy model gradient boosting</li>
<li>dla kobiet rozpatrujemy podzia³ na TERYT,  odciêcia zosta³y wykonane na podstawie funkcji:</li>
</ul>

```{r, eval=FALSE}
teryt.groups$is_linear <- teryt.groups$bool_difs < 0 & teryt.groups$difs < -1e-05 
teryt.groups$is_boost <- teryt.groups$bool_difs > 0 & teryt.groups$difs > 1e-05 
teryt.groups$clf <- teryt.groups$is_linear * 1 + teryt.groups$is_boost * -1
```
 
zatem w zale¿noœci od wielkoœci ró¿nic œrednich znaków (bool_difs) oraz ró¿nic w œrednich (difs) (progi +/-1e-05 zosta³y dobrane na podstawie Wykresu b³êdów -  _patrz poni¿ej_) stosujemy regresjê liniow¹ (clf=1) lub gradient boosting (clf=-1) oraz zdecydowaliœmy, ¿e w przypadku braku wyraŸnej ró¿nicy miêdzy modelami (clf=0) zastosujemy gradient boosting.

__Wykres b³êdów__ (oœ pozioma to numer TERYT):

<center>
<img src="roznice.png" />
</center>

Powy¿szy opis ilustruje drzewo decyzyjne:

<center>
<img src="drzewo.png" />
</center>

#Prezentacja wyników 

Na poni¿szych kartogramach prezentujemy predykcjê na rok 2013 odsetek zachorowañ z podzia³em na p³eæ:

<center>
<img src="kobiety.png" />

<img src="mezczyzni.png" />
<center/>


#Podsumowanie
